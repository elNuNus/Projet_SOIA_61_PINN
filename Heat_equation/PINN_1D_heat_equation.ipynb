{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Projet SOIA 6.1 - PINN\n",
    "## Oscar Agnus, SOIA A3\n"
   ],
   "id": "a098870fcb053660"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Here, we try to simulate the 1D heat equation using a physics-informed neural network (PINN). The heat equation is given by:\n",
    "$$\n",
    "\\frac{\\partial u}{\\partial t} = \\nu \\frac{\\partial^2 u}{\\partial x^2}\n",
    "$$\n",
    "\n",
    "where $u$ is the temperature,\n",
    "$x$ is the space coordinate,\n",
    "$t$ is the time coordinate,\n",
    "and $\\nu$ is the thermal diffusivity.\n"
   ],
   "id": "4db4ced449dbb9bc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T14:26:49.266216Z",
     "start_time": "2024-12-08T14:26:32.134382Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "import pinnde.pde_Solvers as pde_Solvers\n",
    "import pinnde.pde_Initials as pde_Initials\n",
    "import pinnde.pde_Boundaries_2var as pde_Boundaries\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "\n",
    "# Weights and Biases - this is for logging the results\n",
    "import wandb"
   ],
   "id": "5bf6968b06e1971",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Setting up the problem\n",
    "\n",
    "Here, we define the problem in physical terms, and format it so that it can be used by the neural network."
   ],
   "id": "798269329458b05d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Machine learning model",
   "id": "3ecafb20cc2c5ed8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T14:26:49.395310Z",
     "start_time": "2024-12-08T14:26:49.275224Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the model\n",
    "my_model = models.resnet18()\n",
    "my_model.fc = nn.Linear(512, 1)\n",
    "\n",
    "# my_model = torch.nn.Sequential(\n",
    "#     torch.nn.Linear(1, 20),\n",
    "#     torch.nn.Tanh(),\n",
    "#     torch.nn.Linear(20, 20),\n",
    "#     torch.nn.Tanh(),\n",
    "#     torch.nn.Linear(20, 20),\n",
    "#     torch.nn.Tanh(),\n",
    "#     torch.nn.Linear(20, 1)\n",
    "# )\n",
    "\n",
    "model_name = 'resnet18_vanilla'"
   ],
   "id": "d2b252edeea286ec",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T14:26:49.576307Z",
     "start_time": "2024-12-08T14:26:49.571233Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Space domain\n",
    "x_min = 0\n",
    "x_max = 1\n",
    "N_x = 1000 # Number of points in the space domain\n",
    "X = np.linspace(x_min, x_max, N_x) # Discretized space domain\n",
    "X_bc = np.array([x_min, x_max]) # Boundary conditions pointsfqxy \n",
    "\n",
    "# Time domain\n",
    "t_min = 0\n",
    "t_max = 1\n",
    "N_t = 500 # Number of points in the time domain\n",
    "T = np.linspace(t_min, t_max, N_t) # Discretised time domain\n",
    "T_0 = np.array(T[0]) # Initial time\n",
    "\n",
    "\n",
    "# Define useful parameters\n",
    "nu = 0.01 # Thermal diffusivity\n",
    "\n",
    "N_u = 1000          # Number of data points for the solution\n",
    "N_bc = 100          # Number of boundary conditions points\n",
    "N_pde = 10000       # Number of PDE conditions\n",
    "N_sensors = 30000   # Number of sensors\n",
    "N_iv = 100          # Number of initial values\n",
    "\n",
    "# Initial conditions\n",
    "def u_ic(x):\n",
    "    \"\"\"Initial conditions for the heat equation.\"\"\"\n",
    "    return np.sin(np.pi*x)\n",
    "\n",
    "# Boundary conditions\n",
    "def u_bc(x, t):\n",
    "    \"\"\"Boundary conditions for the heat equation.\n",
    "    These can be time-dependent.\"\"\"\n",
    "    u = np.zeros_like(x)\n",
    "    u[0] = 0\n",
    "    u[-1] = 0\n",
    "    return u # Maybe return only the values on the boundary instead of the whole array ?\n",
    "    \n",
    "\n",
    "# Exact solution, or the finite difference solution\n",
    "def u_exact(x, t):\n",
    "    \"\"\"Exact solution of the heat equation.\n",
    "    The solution is given for each instant, and the space domain can be multidimensional.\n",
    "    :param x: space domain, discretized\n",
    "    :param t: time domain, discretized\"\"\"\n",
    "    u = np.zeros((len(t), len(x)))\n",
    "    for i in range(len(t)):\n",
    "        u[i] = np.exp(-np.pi**2*t[i])*np.sin(np.pi*x)\n",
    "    return u"
   ],
   "id": "54e6c665bf2c4558",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Here are defined the loss functions. There are 3 different loss functions:\n",
    "- $L_{data}$: loss function for the data points\n",
    "- $L_{bc}$  :loss function for the boundary conditions\n",
    "- $L_{pde}$ : loss function for the PDE\n",
    "\n",
    "Each one of them will be used with their relative weight, which represent their importance, in the composite loss function."
   ],
   "id": "261960eae8049687"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T14:26:49.593934Z",
     "start_time": "2024-12-08T14:26:49.588856Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Gradient function\n",
    "def grad(outputs, inputs):\n",
    "    \"\"\"Compute the gradient of 'outputs' with respect to 'inputs'.\"\"\"\n",
    "    return tf.gradients(outputs, inputs)[0]\n",
    "    # return torch.autograd(outputs, inputs, grad_outputs=torch.ones_like(outputs), create_graph=True)[0]\n",
    "\n",
    "# Loss functions\n",
    "def loss_bc(u_pred, x_bc, t_bc, u_bc):\n",
    "    \"\"\"Loss function for the boundary conditions.\"\"\"\n",
    "    u_square = u_pred(x_bc, t_bc) # estimation de u aux bords\n",
    "    return tf.reduce_mean(tf.square(u_square - u_bc))\n",
    "\n",
    "def loss_pde(u_pred, x_pde, t_pde):\n",
    "    \"\"\"Loss function for the PDE.\"\"\"\n",
    "    u_x  = grad(u_pred, x_pde)\n",
    "    u_xx = grad(u_x, x_pde)\n",
    "    u_t  = grad(u_pred, t_pde)\n",
    "    return tf.reduce_mean(tf.square(u_t - nu*u_xx))\n",
    "\n",
    "def loss_data(u_pred, u_data):\n",
    "    \"\"\"Loss function for the data points.\"\"\"\n",
    "    return tf.reduce_mean(tf.square(u_pred - u_data))\n",
    "\n",
    "# Weights for the composite loss function\n",
    "w_data = 0.0\n",
    "w_bc   = 1.0\n",
    "w_pde  = 1.0\n",
    "\n",
    "# Composite loss function\n",
    "def loss_composite(u_data, u_pred, x_bc, t_bc, u_bc, x_pde, t_pde):\n",
    "    \"\"\"Composite loss function, combining the three loss functions.\"\"\"\n",
    "    return w_data*loss_data(u_pred, u_data) + w_bc*loss_bc(u_pred, x_bc, t_bc, u_bc) + w_bc*loss_pde(u_pred, x_pde, t_pde)"
   ],
   "id": "56ac23c75d94fc05",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Here we define the training and testing functions. We want to make a checkpoint of the model when the testing loss is minimal.",
   "id": "a3e3ee0db7b7da4e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T14:26:49.610001Z",
     "start_time": "2024-12-08T14:26:49.604726Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Training function \n",
    "def train(model, trainloader, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    n_iter = 500\n",
    "\n",
    "    # Training loop\n",
    "    for n in range(n_iter):\n",
    "    # for inputs in trainloader:\n",
    "        # Reshape to [batch_size, channels, height, width]\n",
    "        # inputs = inputs.reshape(1, 1, 1, 1000)\n",
    "        # inputs = inputs.view()  # Reshape to [batch_size, channels, height, width]\n",
    "    \n",
    "        inputs = torch.tensor(inputs, dtype=torch.float32)\n",
    "\n",
    "\n",
    "        # Move data to device\n",
    "        inputs = inputs.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        print(\"outputs shape :\", outputs.shape)\n",
    "        outputs_bc = outputs(X_bc, T) # estimated u at the boundary\n",
    "        loss = loss_composite(u_exact(X, T), outputs, X_bc, T, outputs_bc, X, T)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Compute running statistics\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        \n",
    "    train_loss = running_loss / len(trainloader)\n",
    "\n",
    "    return train_loss\n",
    "\n",
    "# # Testing function\n",
    "# def test(model, testloader, criterion, device):\n",
    "#     model.eval()\n",
    "#     running_loss = 0.0\n",
    "#     correct = 0\n",
    "#     total = 0\n",
    "# \n",
    "#     with torch.no_grad():\n",
    "#         # Testing loop\n",
    "#         for inputs, labels in testloader:\n",
    "#             # Move data to device\n",
    "#             inputs, labels = inputs.to(device), labels.to(device)\n",
    "#             outputs = model(inputs)\n",
    "#             loss = criterion(outputs, labels)\n",
    "# \n",
    "#             # Compute running statistics\n",
    "#             running_loss += loss.item()\n",
    "#             _, predicted = outputs.max(1)\n",
    "#             total += labels.size(0)\n",
    "#             correct += predicted.eq(labels).sum().item()\n",
    "# \n",
    "#     test_loss = running_loss / len(testloader)\n",
    "#     test_acc = 100. * correct / total\n",
    "#     \n",
    "#     return test_loss, test_acc"
   ],
   "id": "9791d86dd8f4dba2",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Training the model",
   "id": "1e07ba6f30d747e2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Check in the PC configuration if the GPU is available. Cuda needs to be installed to use the GPU with PyTorch.\n",
    "This will speed up the training process."
   ],
   "id": "cbf51716166ca6af"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T14:26:51.092840Z",
     "start_time": "2024-12-08T14:26:49.617548Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Is cuda available: ', torch.cuda.is_available())\n",
    "my_model.to(device)\n",
    "print(f'Using device: {device}')"
   ],
   "id": "f5b0b6bc2b85e1f0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is cuda available:  True\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Here, we load the data and define the data loaders.\n",
    "\n",
    "\n",
    "There isn't any testing data, because we will not use the accuracy metrics to assess the model.\n",
    "\n",
    "The training data `u_data` will be either the exact solution, or some measured data. For now, we will not use any data, meaning `w_data = 0.0`."
   ],
   "id": "7e2cf4a3ecbb3fbb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T14:26:51.107611Z",
     "start_time": "2024-12-08T14:26:51.103611Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Data loaders\n",
    "\n",
    "# trainloader = np.array(u_exact(X, T))\n",
    "trainloader = torch.utils.data.DataLoader(X, batch_size=1, shuffle=True)"
   ],
   "id": "f4f42610636cf8f2",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T14:26:51.467083Z",
     "start_time": "2024-12-08T14:26:51.127472Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Training parameters\n",
    "n_epoch = 10\n",
    "lr = 0.01\n",
    "optimiser = optim.Adam(my_model.parameters(), lr=lr)\n",
    "\n",
    "# List of losses\n",
    "train_loss_list = np.zeros(n_epoch)\n",
    "train_acc_list  = np.zeros(n_epoch)\n",
    "best_test_acc = 0.0\n",
    "\n",
    "# Training\n",
    "for epoch in range(n_epoch):\n",
    "    t0 = time.time()\n",
    "    train_loss = train(my_model, trainloader, optimiser, device)\n",
    "    t1 = time.time()\n",
    "    \n",
    "    print(f'Epoch {epoch+1:03d}, Train Loss: {train_loss:.4f}, Time: {t1-t0:.4f} s')"
   ],
   "id": "167fc435c484cf2e",
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'inputs' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mUnboundLocalError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 14\u001B[0m\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(n_epoch):\n\u001B[0;32m     13\u001B[0m     t0 \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m---> 14\u001B[0m     train_loss \u001B[38;5;241m=\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmy_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrainloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimiser\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     15\u001B[0m     t1 \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m     17\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mEpoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m03d\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, Train Loss: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtrain_loss\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, Time: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mt1\u001B[38;5;241m-\u001B[39mt0\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m s\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "Cell \u001B[1;32mIn[5], line 15\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(model, trainloader, optimizer, device)\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;66;03m# Training loop\u001B[39;00m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m n \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(n_iter):\n\u001B[0;32m     10\u001B[0m \u001B[38;5;66;03m# for inputs in trainloader:\u001B[39;00m\n\u001B[0;32m     11\u001B[0m     \u001B[38;5;66;03m# Reshape to [batch_size, channels, height, width]\u001B[39;00m\n\u001B[0;32m     12\u001B[0m     \u001B[38;5;66;03m# inputs = inputs.reshape(1, 1, 1, 1000)\u001B[39;00m\n\u001B[0;32m     13\u001B[0m     \u001B[38;5;66;03m# inputs = inputs.view()  # Reshape to [batch_size, channels, height, width]\u001B[39;00m\n\u001B[1;32m---> 15\u001B[0m     inputs \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor(\u001B[43minputs\u001B[49m, dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mfloat32)\n\u001B[0;32m     18\u001B[0m     \u001B[38;5;66;03m# Move data to device\u001B[39;00m\n\u001B[0;32m     19\u001B[0m     inputs \u001B[38;5;241m=\u001B[39m inputs\u001B[38;5;241m.\u001B[39mto(device)\n",
      "\u001B[1;31mUnboundLocalError\u001B[0m: cannot access local variable 'inputs' where it is not associated with a value"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Here we initialise the wandb run, which will log the results of the training process.",
   "id": "5473b47a76ac441a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"Projet SOIA 6.1 - PINN\",\n",
    "\n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "    \"learning_rate\": lr,\n",
    "    \"architecture\": \"resnet18\",\n",
    "    \"dataset\": \"heat_equation_custom_solution\",\n",
    "    \"epochs\": n_epoch,\n",
    "    }\n",
    ")"
   ],
   "id": "be8949a7da4051d3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T14:26:51.473089300Z",
     "start_time": "2024-10-27T17:21:25.492208Z"
    }
   },
   "cell_type": "code",
   "source": "# Display the results\n",
   "id": "7f5765d3a878820e",
   "outputs": [],
   "execution_count": 18
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
